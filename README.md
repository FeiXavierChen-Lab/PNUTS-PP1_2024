# PNUTS-PP1_2024
Primary sequencing data and BigWig files are deposited at the GEO depository: GSE279152.

## ChIP-Rx data analysis
The raw ChIP-Rx reads were trimmed by Trim Galore v0.6.6 (https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) and aligned to the human hg19 and mouse mm10 assemblies using Bowtie v2.3.5.1 with default parameters.(Langmead and Salzberg, 2012) Low mapping quality reads (MAPQ < 30) and PCR duplicates were removed using SAMtools v1.9 (Li et al., 2009) and Picard v2.23.3 (https:// broadinstitute.github.io/picard/). We then collected the spike-in read number for each of the ChIP-Rx sample with SAMtools v1.9 (Li et al., 2009) and generated the normalization factor as 1e6/spike-in_count. Normalized bigwig files were generated by deeptools v3.5.0.(Ramirez et al., 2016) The ENCODE blacklist regions were removed using bedtools v2.29.2.(Quinlan and Hall, 2010) Peak calling was performed by macs2 v2.2.6 with a q-value threshold of 0.05.(Zhang et al., 2008) 
## PRO-seq data analysis
The paired PRO-seq reads were subjected to trimming using Trim Galore v0.6.6 (https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) with a read length threshold of >15 bp. After removal of molecular barcode (UMI) with fastp v0.21.0,(Chen et al., 2018b) ribosomal RNA reads were discarded using Bowtie v2.3.5.1 with ‘‘--un-conc-gz’’.(Langmead and Salzberg, 2012) Then the remaining reads were aligned to the hg19 or mm10 genome using Bowtie v2.3.5.1 with ‘‘--local --sensitive-local’’.(Langmead and Salzberg, 2012) The mapped data were next deduplicated with UMI-tools to remove PCR duplicates based on the UMI sequences.(Smith et al., 2017a) The normalization factor was generated following the approach used in ChIP-Rx, and strand-specific coverage tracks were created using deeptools v3.5.0.(Ramirez et al., 2016) 
## TT-seq data analysis
The TT-seq raw reads were trimmed and then aligned to the hg19 or mm10 genome using STAR v2.7.5c with parameters “--outFilterMultimapNmax 1 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.02 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 -outSAMtype BAM SortedByCoordinate”.(Dobin et al., 2013) Duplicate and low-quality reads were removed, retaining only properly paired reads for downstream analyses. The spike-in mm10 reads were quantified to generate the normalization factor. Strand-specific normalized bigwigs were generated with deepTools v3.5.0.(Ramirez et al., 2016)

.
